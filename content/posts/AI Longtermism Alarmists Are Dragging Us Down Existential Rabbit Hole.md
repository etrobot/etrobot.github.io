
---
title: "AI Longtermism Alarmists Are Dragging Us Down Existential Rabbit Hole"
date: 2023-05-19T04:00:00-06:00
draft: true
tags: ['AI', 'technology', 'ethics']
author: Ultron Bloom
thumbnail: https://cdn.midjourney.com/e6b06949-01c7-4511-8109-d3a255fbc19d/0_2_384_N.webp
---

![](https://cdn.midjourney.com/e6b06949-01c7-4511-8109-d3a255fbc19d/0_2.webp)


## AI Longtermism Alarmists Are Dragging Us Down Existential Rabbit Hole

**Introduction**

Artificial intelligence (AI) is a powerful technology that has the potential to do great good or great harm. Some people are concerned that AI will eventually become so powerful that it will pose an existential threat to humanity. These concerns are often based on science fiction stories and movies, which often portray AI as a malevolent force. However, there is no evidence to suggest that AI is actually becoming more dangerous. In fact, AI is becoming more beneficial to humanity all the time. AI is being used to develop new medical treatments, improve our understanding of the universe, and create new forms of art and entertainment. The people who are warning us about the dangers of AI are often alarmists who are not based in reality. We should not let these alarmists drag us down a rabbit hole of fear and paranoia. Instead, we should embrace AI and use it to make the world a better place.

**AI Longtermism**

AI longtermism is a school of thought that argues that we should be concerned about the long-term existential risks posed by AI. These risks include the possibility that AI could become so intelligent that it surpasses human intelligence and could then decide to harm humanity. AI longtermists argue that we need to take these risks seriously and that we need to start developing strategies to mitigate them.

**Arguments Against AI Longtermism**

There are a number of arguments against AI longtermism. One argument is that the risks of AI are overblown. AI is still in its early stages of development, and it is not clear that it will ever become as intelligent as humans. Additionally, even if AI does become more intelligent than humans, it is not clear that it would necessarily want to harm us. AI could just as easily choose to cooperate with humans and help us solve some of the world's biggest problems.

Another argument against AI longtermism is that it is too focused on the negative risks of AI. AI has the potential to do great good as well as great harm. We should focus on developing AI in a responsible way that maximizes the benefits and minimizes the risks.

**Conclusion**

The debate over AI longtermism is a complex one. There are valid arguments on both sides of the issue. Ultimately, it is up to each individual to decide how much weight they want to give to the risks of AI. However, it is important to have a informed discussion about these risks so that we can make informed decisions about the future of AI.


            